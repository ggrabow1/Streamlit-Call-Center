{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    " \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "project_dir = '/sasinside/userdata/gegrab/resources/hmeq'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.   Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CALL_CENTER_ID  DAILY_CALLS  MONTHLY_CALLS  CALL_TARGET       REASON  \\\n",
      "0          215458          214          909.0       1217.0  ProdFailure   \n",
      "1          954367          214          445.0        809.0  ProdFailure   \n",
      "2          559293          214          494.0        694.0  ProdFailure   \n",
      "3          289495          214          643.0        993.0   ProdGlitch   \n",
      "4          123218          214          922.0       1337.0  ProdFailure   \n",
      "\n",
      "   MONTHS_CUSTOMER  NEGATIVE_RATING  DAYS_PROD_OUT_OF_SERVICE  PRODUCT_AGE  \\\n",
      "0         3.000000          0.00000                  0.000000   221.515426   \n",
      "1         8.922268          0.25457                  0.449442   179.766275   \n",
      "2        25.000000          0.00000                  0.000000   314.638958   \n",
      "3        18.000000          0.00000                  0.000000   627.702389   \n",
      "4        11.000000          0.00000                  0.000000    81.446380   \n",
      "\n",
      "   CALL_INQUIRIES  NUM_CALLERS  CALL_TIME PRODUCT_TYPE  \n",
      "0        2.000000    26.000000  34.885541       Server  \n",
      "1        1.186055    21.296096  37.827219        Other  \n",
      "2        2.000000    32.000000  35.982084        Other  \n",
      "3        1.000000    23.000000  20.688715       Laptop  \n",
      "4        3.000000    15.000000  41.395462        Other  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sasinside/miniconda3/envs/pytorch2021/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CALL_CENTER_ID</th>\n",
       "      <th>ESCALATED</th>\n",
       "      <th>DAILY_CALLS</th>\n",
       "      <th>MONTHLY_CALLS</th>\n",
       "      <th>CALL_TARGET</th>\n",
       "      <th>REASON</th>\n",
       "      <th>MONTHS_CUSTOMER</th>\n",
       "      <th>NEGATIVE_RATING</th>\n",
       "      <th>DAYS_PROD_OUT_OF_SERVICE</th>\n",
       "      <th>PRODUCT_AGE</th>\n",
       "      <th>CALL_INQUIRIES</th>\n",
       "      <th>NUM_CALLERS</th>\n",
       "      <th>CALL_TIME</th>\n",
       "      <th>PRODUCT_TYPE</th>\n",
       "      <th>FEEDBACK</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215458</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>909.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>ProdFailure</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>221.515426</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>34.885541</td>\n",
       "      <td>Server</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>954367</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>445.0</td>\n",
       "      <td>809.0</td>\n",
       "      <td>ProdFailure</td>\n",
       "      <td>8.922268</td>\n",
       "      <td>0.25457</td>\n",
       "      <td>0.449442</td>\n",
       "      <td>179.766275</td>\n",
       "      <td>1.186055</td>\n",
       "      <td>21.296096</td>\n",
       "      <td>37.827219</td>\n",
       "      <td>Other</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>559293</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>494.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>ProdFailure</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>314.638958</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>35.982084</td>\n",
       "      <td>Other</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289495</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>643.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>ProdGlitch</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>627.702389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.688715</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123218</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>922.0</td>\n",
       "      <td>1337.0</td>\n",
       "      <td>ProdFailure</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.446380</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>41.395462</td>\n",
       "      <td>Other</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CALL_CENTER_ID  ESCALATED  DAILY_CALLS  MONTHLY_CALLS  CALL_TARGET  \\\n",
       "0          215458          0          214          909.0       1217.0   \n",
       "1          954367          0          214          445.0        809.0   \n",
       "2          559293          0          214          494.0        694.0   \n",
       "3          289495          0          214          643.0        993.0   \n",
       "4          123218          0          214          922.0       1337.0   \n",
       "\n",
       "        REASON  MONTHS_CUSTOMER  NEGATIVE_RATING  DAYS_PROD_OUT_OF_SERVICE  \\\n",
       "0  ProdFailure         3.000000          0.00000                  0.000000   \n",
       "1  ProdFailure         8.922268          0.25457                  0.449442   \n",
       "2  ProdFailure        25.000000          0.00000                  0.000000   \n",
       "3   ProdGlitch        18.000000          0.00000                  0.000000   \n",
       "4  ProdFailure        11.000000          0.00000                  0.000000   \n",
       "\n",
       "   PRODUCT_AGE  CALL_INQUIRIES  NUM_CALLERS  CALL_TIME PRODUCT_TYPE  \\\n",
       "0   221.515426        2.000000    26.000000  34.885541       Server   \n",
       "1   179.766275        1.186055    21.296096  37.827219        Other   \n",
       "2   314.638958        2.000000    32.000000  35.982084        Other   \n",
       "3   627.702389        1.000000    23.000000  20.688715       Laptop   \n",
       "4    81.446380        3.000000    15.000000  41.395462        Other   \n",
       "\n",
       "                                            FEEDBACK  Sentiment  \n",
       "0  So there is no way for me to plug it in here i...          0  \n",
       "1                        Good case, Excellent value.          1  \n",
       "2                             Great for the jawbone.          1  \n",
       "3  Tied to charger for conversations lasting more...          0  \n",
       "4                                  The mic is great.          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data_orig/call_center_v2.csv')\n",
    "#df = df.dropna() # Or some way to treat missing values \n",
    "\n",
    "callcenter = df.drop(['ESCALATED', 'FEEDBACK', 'Sentiment'], axis=1)\n",
    "\n",
    " \n",
    " \n",
    "class_inputs   = ['REASON', 'PRODUCT_TYPE']\n",
    " \n",
    "target         = [\"ESCALATED\"]\n",
    "numeric_inputs = ['DAILY_CALLS', 'MONTHLY_CALLS', 'CALL_TARGET', 'MONTHS_CUSTOMER', \n",
    "                  'NEGATIVE_RATING', 'DAYS_PROD_OUT_OF_SERVICE', 'PRODUCT_AGE', 'CALL_INQUIRIES','NUM_CALLERS','CALL_TIME']\n",
    "\n",
    "impute_values = df[numeric_inputs].mean()\n",
    "pickle.dump(impute_values, open('/sasinside/userdata/gegrab/resources/hmeq/callcenter_impute.pickle','wb'))\n",
    "   \n",
    "    \n",
    "df           =df.fillna(impute_values)\n",
    "df.REASON.replace(np.nan,'ProdFailure',regex = True, inplace=True)\n",
    "df.PRODUCT_TYPE.replace(np.nan,'Other',regex = True, inplace=True)\n",
    "\n",
    "\n",
    "sample =df.head()\n",
    "sample.drop(['ESCALATED', 'FEEDBACK', 'Sentiment'], axis=1, inplace=True)\n",
    " \n",
    "sample.to_csv('Data_orig/CALLCENTER_test2.csv', index=False)\n",
    " \n",
    "print(sample.head())\n",
    "#callcenter.head()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='ESCALATED', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAARb0lEQVR4nO3de7BdZXnH8e9PIl7qBZBTxAQMUzN1UFvUM4BVZxQrF2sNddTCaIk2TvwDW+lULXTG0qJMtdpStNWRFjQwrUilFrSMNgWs44wXgiLXIqmKJIKJBPFOG/r0j/0euwnn5N1I1jknnO9nZs9e61nvWvuBCfmx1nr32qkqJEnalYctdAOSpMXPsJAkdRkWkqQuw0KS1GVYSJK6DAtJUtegYZHkm0muS3JNko2ttl+SDUluae/7tnqSvDfJpiTXJnnW2HHWtPG3JFkzZM+SpPubjzOLF1bVYVU13dZPBS6vqlXA5W0d4DhgVXutAz4Ao3ABTgeOAA4HTp8JGEnS/FiIy1CrgfVteT1w/Fj9/Br5ArBPkgOBY4ANVbW9qu4CNgDHznPPkrSkLRv4+AX8W5ICPlhV5wAHVNXtbfsdwAFteTlw29i+m1ttrvqc9t9//1q5cuWD716SlpCrr776u1U1Ndu2ocPieVW1JckvAhuS/Of4xqqqFiQPWpJ1jC5fcfDBB7Nx48bdcVhJWjKS3DrXtkEvQ1XVlva+Ffg4o3sO32mXl2jvW9vwLcBBY7uvaLW56jt/1jlVNV1V01NTswajJOnnNFhYJPmFJI+dWQaOBq4HLgVmZjStAS5py5cCJ7VZUUcCd7fLVZ8Gjk6yb7uxfXSrSZLmyZCXoQ4APp5k5nP+sao+leQq4KIka4FbgVe18ZcBLwE2AT8GXgdQVduTvB24qo07o6q2D9i3JGkneSg+onx6erq8ZyFJD0ySq8e+5nAffoNbktRlWEiSugwLSVKXYSFJ6jIsJEldQ3+De4/17Lecv9AtaBG6+t0nLXQL0oLwzEKS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2Dh0WSvZJ8Jckn2/ohSb6YZFOSjybZu9Uf0dY3te0rx45xWqvfnOSYoXuWJN3XfJxZvAm4aWz9XcBZVfUU4C5gbauvBe5q9bPaOJIcCpwAPA04Fnh/kr3moW9JUjNoWCRZAfwG8PdtPcBRwMfakPXA8W15dVunbX9RG78auLCq7qmqbwCbgMOH7FuSdF9Dn1n8NfBW4H/b+hOA71XVjra+GVjelpcDtwG07Xe38T+rz7LPzyRZl2Rjko3btm3bzf8YkrS0DRYWSV4KbK2qq4f6jHFVdU5VTVfV9NTU1Hx8pCQtGcsGPPZzgZcleQnwSOBxwNnAPkmWtbOHFcCWNn4LcBCwOcky4PHAnWP1GeP7SJLmwWBnFlV1WlWtqKqVjG5QX1FVrwauBF7Rhq0BLmnLl7Z12vYrqqpa/YQ2W+oQYBXwpaH6liTd35BnFnP5I+DCJO8AvgKc2+rnAhck2QRsZxQwVNUNSS4CbgR2ACdX1b3z37YkLV3zEhZV9RngM23568wym6mqfgq8co79zwTOHK5DSdKu+A1uSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoaLCySPDLJl5J8NckNSf6s1Q9J8sUkm5J8NMnerf6Itr6pbV85dqzTWv3mJMcM1bMkaXZDnlncAxxVVb8KHAYcm+RI4F3AWVX1FOAuYG0bvxa4q9XPauNIcihwAvA04Fjg/Un2GrBvSdJOBguLGvlhW314exVwFPCxVl8PHN+WV7d12vYXJUmrX1hV91TVN4BNwOFD9S1Jur9B71kk2SvJNcBWYAPwX8D3qmpHG7IZWN6WlwO3AbTtdwNPGK/Pso8kaR4MGhZVdW9VHQasYHQ28NShPivJuiQbk2zctm3bUB8jSUvSvMyGqqrvAVcCzwH2SbKsbVoBbGnLW4CDANr2xwN3jtdn2Wf8M86pqumqmp6amhriH0OSlqwhZ0NNJdmnLT8KeDFwE6PQeEUbtga4pC1f2tZp26+oqmr1E9psqUOAVcCXhupbknR/y/pDfm4HAuvbzKWHARdV1SeT3AhcmOQdwFeAc9v4c4ELkmwCtjOaAUVV3ZDkIuBGYAdwclXdO2DfkqSdDBYWVXUt8MxZ6l9nltlMVfVT4JVzHOtM4Mzd3aMkaTJ+g1uS1GVYSJK6DAtJUpdhIUnqMiwkSV0ThUWSyyepSZIemnY5dTbJI4FHA/sn2RdI2/Q4fD6TJC0Zve9ZvAE4BXgScDX/HxbfB/5muLYkSYvJLsOiqs4Gzk7ye1X1vnnqSZK0yEz0De6qel+SXwNWju9TVecP1JckaRGZKCySXAD8EnANMPNcpgIMC0laAiZ9NtQ0cGh7CqwkaYmZ9HsW1wNPHLIRSdLiNemZxf7AjUm+BNwzU6yqlw3SlSRpUZk0LP50yCYkSYvbpLOh/mPoRiRJi9eks6F+wGj2E8DewMOBH1XV44ZqTJK0eEx6ZvHYmeUkAVYDRw7VlCRpcXnAT52tkX8Bjtn97UiSFqNJL0O9fGz1YYy+d/HTQTqSJC06k86G+s2x5R3ANxldipIkLQGT3rN43dCNSJIWr0l//GhFko8n2dpeFydZMXRzkqTFYdIb3B8CLmX0uxZPAj7RapKkJWDSsJiqqg9V1Y72+jAwNWBfkqRFZNKwuDPJa5Ls1V6vAe4csjFJ0uIxaVj8LvAq4A7gduAVwGsH6kmStMhMOnX2DGBNVd0FkGQ/4D2MQkSS9BA36ZnFr8wEBUBVbQeeOUxLkqTFZtKweFiSfWdW2pnFpGclkqQ93KR/4f8l8Pkk/9TWXwmcOUxLkqTFZtJvcJ+fZCNwVCu9vKpuHK4tSdJiMvGlpBYOBoQkLUEP+BHlkqSlZ7CwSHJQkiuT3JjkhiRvavX9kmxIckt737fVk+S9STYluTbJs8aOtaaNvyXJmqF6liTNbsgzix3AH1bVoYx+Ve/kJIcCpwKXV9Uq4PK2DnAcsKq91gEfgJ/NvDodOAI4HDh9fGaWJGl4g4VFVd1eVV9uyz8AbgKWM/odjPVt2Hrg+La8Gji//RLfF4B9khzI6Bf5NlTV9vZdjw3AsUP1LUm6v3m5Z5FkJaMv8X0ROKCqbm+b7gAOaMvLgdvGdtvcanPVJUnzZPCwSPIY4GLglKr6/vi2qiqgdtPnrEuyMcnGbdu27Y5DSpKaQcMiycMZBcU/VNU/t/J32uUl2vvWVt8CHDS2+4pWm6t+H1V1TlVNV9X01JRPT5ek3WnI2VABzgVuqqq/Gtt0KTAzo2kNcMlY/aQ2K+pI4O52uerTwNFJ9m03to9uNUnSPBny+U7PBX4HuC7JNa32x8A7gYuSrAVuZfToc4DLgJcAm4AfA6+D0UMLk7wduKqNO6M9yFCSNE8GC4uq+hyQOTa/aJbxBZw8x7HOA87bfd1Jkh4Iv8EtSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1LVsoRuQ9MB864xnLHQLWoQO/pPrBj2+ZxaSpC7DQpLUZVhIkroMC0lS12BhkeS8JFuTXD9W2y/JhiS3tPd9Wz1J3ptkU5JrkzxrbJ81bfwtSdYM1a8kaW5Dnll8GDh2p9qpwOVVtQq4vK0DHAesaq91wAdgFC7A6cARwOHA6TMBI0maP4OFRVV9Fti+U3k1sL4trweOH6ufXyNfAPZJciBwDLChqrZX1V3ABu4fQJKkgc33PYsDqur2tnwHcEBbXg7cNjZuc6vNVb+fJOuSbEyycdu2bbu3a0la4hbsBndVFVC78XjnVNV0VU1PTU3trsNKkpj/sPhOu7xEe9/a6luAg8bGrWi1ueqSpHk032FxKTAzo2kNcMlY/aQ2K+pI4O52uerTwNFJ9m03to9uNUnSPBrs2VBJPgK8ANg/yWZGs5reCVyUZC1wK/CqNvwy4CXAJuDHwOsAqmp7krcDV7VxZ1TVzjfNJUkDGywsqurEOTa9aJaxBZw8x3HOA87bja1Jkh4gv8EtSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV17TFgkOTbJzUk2JTl1ofuRpKVkjwiLJHsBfwscBxwKnJjk0IXtSpKWjj0iLIDDgU1V9fWq+m/gQmD1AvckSUvGnhIWy4HbxtY3t5okaR4sW+gGdpck64B1bfWHSW5eyH4eYvYHvrvQTSwGec+ahW5B9+WfzRmnZ3cc5clzbdhTwmILcNDY+opW+5mqOgc4Zz6bWiqSbKyq6YXuQ9qZfzbnz55yGeoqYFWSQ5LsDZwAXLrAPUnSkrFHnFlU1Y4kbwQ+DewFnFdVNyxwW5K0ZOwRYQFQVZcBly10H0uUl/e0WPlnc56kqha6B0nSIren3LOQJC0gw0K75GNWtBglOS/J1iTXL3QvS4VhoTn5mBUtYh8Gjl3oJpYSw0K74mNWtChV1WeB7Qvdx1JiWGhXfMyKJMCwkCRNwLDQrnQfsyJpaTAstCs+ZkUSYFhoF6pqBzDzmJWbgIt8zIoWgyQfAT4P/HKSzUnWLnRPD3V+g1uS1OWZhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLLXlJ7k1yzdjr1FZ/aZKvJPlqkhuTvGFsn5OSXJ/kujbmzWPbliXZluSdO33OZ5LM+nvRSY5PUkme2ta/2Hr5VjvWTG8rk3yzfe5M7b1tnw8n+Ubr92tJzk+yYoh/Z1p69phfypMG9JOqOmy8kOThjH6F7fCq2pzkEcDKtu044BTg6Kr6dtt20tjuLwa+BrwyyWk12fz0E4HPtffTq+qI9lmvBaar6o1jvQG8sKq+O8tx3lJVH8to0CnAFUme3h4EKf3cPLOQZvdYRv8zdSdAVd1TVTe3bacBb66qb49t+7uxfU8Ezga+BTyn90FJHgM8D1jL6FvyD1qNnAXcwegR89KDYlhI8KidLkP9dlVtZ/Rok1uTfCTJq5PM/PfydODq2Q6U5JHArwOfAD7CKDh6VgOfqqqvAXcmefYE+1w51u8f7GLcl4GnTnA8aZe8DCXNchkKoKpen+QZjP7yfzOjy0uv7RzrpcCVVfWTJBcDb0tySlXdu4t9Zs5EYPSbIScyRxiNmesy1M4ywRipy7CQdqGqrgOuS3IB8A1GYXED8Gzgill2ORF4XpJvtvUnAEcBG2Y7fpL92vZnJClgL6CSvGXCex09zwQu3w3H0RLnZShpFkkek+QFY6XDgFvb8p8D707yxDZ27ySvT/I44PnAwVW1sqpWAiez60tRrwAuqKont30OYhRKz3+Q/SfJ7wMHAp96MMeSwDMLCdo9i7H1TwFnAm9N8kHgJ8CPaJegquqyJAcA/95mHRVwHvBbwBVVdc/YsS4B/qLNmAL41yT/05Y/D+wPvGunfi5mFDCf3UXPVyaZubR1bVXNzMZ6d5K3AY8GvsDocpUzofSg+dRZSVKXl6EkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6vo/AiGlANuB6b4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'ESCALATED', data=df)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.  Create Input and Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DAILY_CALLS  MONTHLY_CALLS  CALL_TARGET       REASON  MONTHS_CUSTOMER  \\\n",
      "0          214          909.0       1217.0  ProdFailure         3.000000   \n",
      "1          214          445.0        809.0  ProdFailure         8.922268   \n",
      "2          214          494.0        694.0  ProdFailure        25.000000   \n",
      "3          214          643.0        993.0   ProdGlitch        18.000000   \n",
      "4          214          922.0       1337.0  ProdFailure        11.000000   \n",
      "\n",
      "   NEGATIVE_RATING  DAYS_PROD_OUT_OF_SERVICE  PRODUCT_AGE  CALL_INQUIRIES  \\\n",
      "0          0.00000                  0.000000   221.515426        2.000000   \n",
      "1          0.25457                  0.449442   179.766275        1.186055   \n",
      "2          0.00000                  0.000000   314.638958        2.000000   \n",
      "3          0.00000                  0.000000   627.702389        1.000000   \n",
      "4          0.00000                  0.000000    81.446380        3.000000   \n",
      "\n",
      "   NUM_CALLERS  CALL_TIME PRODUCT_TYPE  \n",
      "0    26.000000  34.885541       Server  \n",
      "1    21.296096  37.827219        Other  \n",
      "2    32.000000  35.982084        Other  \n",
      "3    23.000000  20.688715       Laptop  \n",
      "4    15.000000  41.395462        Other  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = df.iloc[:,1]\n",
    "X = df.iloc[:,2:14] \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "# print(y.head())\n",
    "print(X.head())\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.  Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1580\n",
      "1     387\n",
      "Name: ESCALATED, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAILY_CALLS</th>\n",
       "      <th>MONTHLY_CALLS</th>\n",
       "      <th>CALL_TARGET</th>\n",
       "      <th>REASON</th>\n",
       "      <th>MONTHS_CUSTOMER</th>\n",
       "      <th>NEGATIVE_RATING</th>\n",
       "      <th>DAYS_PROD_OUT_OF_SERVICE</th>\n",
       "      <th>PRODUCT_AGE</th>\n",
       "      <th>CALL_INQUIRIES</th>\n",
       "      <th>NUM_CALLERS</th>\n",
       "      <th>CALL_TIME</th>\n",
       "      <th>PRODUCT_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5046</th>\n",
       "      <td>171</td>\n",
       "      <td>737.170893</td>\n",
       "      <td>960.0</td>\n",
       "      <td>ProdFailure</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>327.001791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.498670</td>\n",
       "      <td>Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>84</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>550.0</td>\n",
       "      <td>ProdFailure</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.433333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.779915</td>\n",
       "      <td>Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>276</td>\n",
       "      <td>543.000000</td>\n",
       "      <td>942.0</td>\n",
       "      <td>ProdFailure</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>188.393742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.833312</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>137</td>\n",
       "      <td>358.000000</td>\n",
       "      <td>666.0</td>\n",
       "      <td>ProdFailure</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.901479</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.702473</td>\n",
       "      <td>Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>99</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>ProdFailure</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.094765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>17.257117</td>\n",
       "      <td>Software</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DAILY_CALLS  MONTHLY_CALLS  CALL_TARGET       REASON  MONTHS_CUSTOMER  \\\n",
       "5046          171     737.170893        960.0  ProdFailure             27.0   \n",
       "2639           84     439.000000        550.0  ProdFailure              1.0   \n",
       "1047          276     543.000000        942.0  ProdFailure             24.0   \n",
       "4089          137     358.000000        666.0  ProdFailure             22.0   \n",
       "2984           99     740.000000       1083.0  ProdFailure              1.0   \n",
       "\n",
       "      NEGATIVE_RATING  DAYS_PROD_OUT_OF_SERVICE  PRODUCT_AGE  CALL_INQUIRIES  \\\n",
       "5046              0.0                       0.0   327.001791             0.0   \n",
       "2639              0.0                       0.0   169.433333             1.0   \n",
       "1047              1.0                       2.0   188.393742             1.0   \n",
       "4089              0.0                       0.0   231.901479             2.0   \n",
       "2984              0.0                       0.0   246.094765             0.0   \n",
       "\n",
       "      NUM_CALLERS  CALL_TIME PRODUCT_TYPE  \n",
       "5046         15.0  12.498670     Software  \n",
       "2639         21.0  33.779915     Software  \n",
       "1047         19.0  26.833312        Other  \n",
       "4089         29.0  26.702473     Software  \n",
       "2984         36.0  17.257117     Software  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "\n",
    "count = y_test.value_counts()\n",
    "print(count)\n",
    "\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sasinside/miniconda3/envs/pytorch2021/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/tmp/ipykernel_31952/657950375.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train.drop(class_inputs,1,inplace=True)\n",
      "/sasinside/miniconda3/envs/pytorch2021/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/tmp/ipykernel_31952/657950375.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test.drop(class_inputs,1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse = False, handle_unknown=\"ignore\")\n",
    "enc =  ohe.fit_transform(X_train[class_inputs])\n",
    "\n",
    "X_train[ohe.get_feature_names(class_inputs)] = pd.DataFrame(enc, index=X_train.index)\n",
    "X_train.drop(class_inputs,1,inplace=True)\n",
    "#print(X_train.head())\n",
    "\n",
    "enc2 =  ohe.fit_transform(X_test[class_inputs])\n",
    "X_test[ohe.get_feature_names(class_inputs)] = pd.DataFrame(enc2, index=X_test.index)\n",
    "X_test.drop(class_inputs,1,inplace=True)\n",
    "#print(X_test.head())\n",
    " \n",
    "pickle.dump(ohe, open(project_dir+\"/callcenter_pytorch_encoder.pickle\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DAILY_CALLS  MONTHLY_CALLS  CALL_TARGET  MONTHS_CUSTOMER  \\\n",
      "2660           85          540.0        625.0              4.0   \n",
      "5603          198          138.0        855.0             20.0   \n",
      "403           235          548.0        870.0              3.5   \n",
      "5649          200         1263.0       1714.0             26.0   \n",
      "903           265         2407.0       2676.0              6.0   \n",
      "\n",
      "      NEGATIVE_RATING  DAYS_PROD_OUT_OF_SERVICE  PRODUCT_AGE  CALL_INQUIRIES  \\\n",
      "2660          0.00000                       1.0   313.466667             0.0   \n",
      "5603          0.00000                       0.0   229.518295             3.0   \n",
      "403           0.00000                       1.0   223.200000             0.0   \n",
      "5649          0.25457                       5.0   329.566667             1.0   \n",
      "903           0.00000                       0.0   229.307026             1.0   \n",
      "\n",
      "      NUM_CALLERS  CALL_TIME  REASON_ProdFailure  REASON_ProdGlitch  \\\n",
      "2660         10.0  33.779915                 1.0                0.0   \n",
      "5603         40.0  35.311066                 1.0                0.0   \n",
      "403          17.0  33.779915                 1.0                0.0   \n",
      "5649         28.0  33.779915                 1.0                0.0   \n",
      "903          50.0  37.740919                 0.0                1.0   \n",
      "\n",
      "      PRODUCT_TYPE_Desktop  PRODUCT_TYPE_FARMING  PRODUCT_TYPE_Laptop  \\\n",
      "2660                   0.0                   0.0                  0.0   \n",
      "5603                   0.0                   0.0                  0.0   \n",
      "403                    0.0                   0.0                  0.0   \n",
      "5649                   1.0                   0.0                  0.0   \n",
      "903                    0.0                   0.0                  0.0   \n",
      "\n",
      "      PRODUCT_TYPE_Other  PRODUCT_TYPE_Server  PRODUCT_TYPE_Software  \n",
      "2660                 1.0                  0.0                    0.0  \n",
      "5603                 1.0                  0.0                    0.0  \n",
      "403                  1.0                  0.0                    0.0  \n",
      "5649                 0.0                  0.0                    0.0  \n",
      "903                  0.0                  1.0                    0.0  \n"
     ]
    }
   ],
   "source": [
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DAILY_CALLS  MONTHLY_CALLS  CALL_TARGET  MONTHS_CUSTOMER  \\\n",
      "2660           85          540.0        625.0              4.0   \n",
      "5603          198          138.0        855.0             20.0   \n",
      "403           235          548.0        870.0              3.5   \n",
      "5649          200         1263.0       1714.0             26.0   \n",
      "903           265         2407.0       2676.0              6.0   \n",
      "\n",
      "      NEGATIVE_RATING  DAYS_PROD_OUT_OF_SERVICE  PRODUCT_AGE  CALL_INQUIRIES  \\\n",
      "2660          0.00000                       1.0   313.466667             0.0   \n",
      "5603          0.00000                       0.0   229.518295             3.0   \n",
      "403           0.00000                       1.0   223.200000             0.0   \n",
      "5649          0.25457                       5.0   329.566667             1.0   \n",
      "903           0.00000                       0.0   229.307026             1.0   \n",
      "\n",
      "      NUM_CALLERS  CALL_TIME  REASON_ProdFailure  REASON_ProdGlitch  \\\n",
      "2660         10.0  33.779915                 1.0                0.0   \n",
      "5603         40.0  35.311066                 1.0                0.0   \n",
      "403          17.0  33.779915                 1.0                0.0   \n",
      "5649         28.0  33.779915                 1.0                0.0   \n",
      "903          50.0  37.740919                 0.0                1.0   \n",
      "\n",
      "      PRODUCT_TYPE_Desktop  PRODUCT_TYPE_FARMING  PRODUCT_TYPE_Laptop  \\\n",
      "2660                   0.0                   0.0                  0.0   \n",
      "5603                   0.0                   0.0                  0.0   \n",
      "403                    0.0                   0.0                  0.0   \n",
      "5649                   1.0                   0.0                  0.0   \n",
      "903                    0.0                   0.0                  0.0   \n",
      "\n",
      "      PRODUCT_TYPE_Other  PRODUCT_TYPE_Server  PRODUCT_TYPE_Software  \n",
      "2660                 1.0                  0.0                    0.0  \n",
      "5603                 1.0                  0.0                    0.0  \n",
      "403                  1.0                  0.0                    0.0  \n",
      "5649                 0.0                  0.0                    0.0  \n",
      "903                  0.0                  1.0                    0.0  \n"
     ]
    }
   ],
   "source": [
    "print(X_test.head())\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "# fit scaler on the training dataset\n",
    "#scaler.fit(X_train)\n",
    "#X_train_scaled = scaler.transform(X_train)\n",
    "pickle.dump(scaler, open('/sasinside/userdata/gegrab/resources/hmeq/callcenter_pytorch_scaler.pickle', 'wb'))\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.  Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.  Define Custom Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "#test_tensor = torch.Tensor(test.values)\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train.values))\n",
    "                       #torch.Float(y_train))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.  Define Neural Net Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 18.      \n",
    "        self.layer_1 = nn.Linear(18, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "         \n",
    "       \n",
    "        return x\n",
    "    \n",
    "net = binaryClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "###################### OUTPUT ######################\n",
    "cuda:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=18, out_features=64, bias=True)\n",
      "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model2 = binaryClassification()\n",
    "model2.to(device)\n",
    "print(model2)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.56653 | Acc: 73.810\n",
      "Epoch 002: | Loss: 0.45200 | Acc: 82.381\n",
      "Epoch 003: | Loss: 0.36850 | Acc: 86.429\n",
      "Epoch 004: | Loss: 0.31866 | Acc: 87.810\n",
      "Epoch 005: | Loss: 0.29316 | Acc: 88.460\n",
      "Epoch 006: | Loss: 0.27268 | Acc: 89.635\n",
      "Epoch 007: | Loss: 0.25647 | Acc: 90.079\n",
      "Epoch 008: | Loss: 0.23769 | Acc: 90.857\n",
      "Epoch 009: | Loss: 0.22745 | Acc: 91.095\n",
      "Epoch 010: | Loss: 0.21280 | Acc: 92.032\n",
      "Epoch 011: | Loss: 0.20213 | Acc: 92.524\n",
      "Epoch 012: | Loss: 0.18848 | Acc: 93.032\n",
      "Epoch 013: | Loss: 0.17902 | Acc: 93.460\n",
      "Epoch 014: | Loss: 0.17100 | Acc: 93.698\n",
      "Epoch 015: | Loss: 0.15808 | Acc: 94.206\n",
      "Epoch 016: | Loss: 0.15046 | Acc: 94.476\n",
      "Epoch 017: | Loss: 0.14133 | Acc: 94.698\n",
      "Epoch 018: | Loss: 0.12694 | Acc: 95.540\n",
      "Epoch 019: | Loss: 0.12930 | Acc: 95.476\n",
      "Epoch 020: | Loss: 0.11801 | Acc: 95.825\n",
      "Epoch 021: | Loss: 0.10629 | Acc: 96.397\n",
      "Epoch 022: | Loss: 0.10919 | Acc: 96.079\n",
      "Epoch 023: | Loss: 0.10183 | Acc: 96.476\n",
      "Epoch 024: | Loss: 0.09679 | Acc: 96.254\n",
      "Epoch 025: | Loss: 0.09534 | Acc: 96.460\n",
      "Epoch 026: | Loss: 0.08343 | Acc: 97.238\n",
      "Epoch 027: | Loss: 0.08673 | Acc: 96.730\n",
      "Epoch 028: | Loss: 0.08381 | Acc: 96.857\n",
      "Epoch 029: | Loss: 0.07560 | Acc: 97.222\n",
      "Epoch 030: | Loss: 0.07346 | Acc: 97.492\n",
      "Epoch 031: | Loss: 0.07358 | Acc: 97.302\n",
      "Epoch 032: | Loss: 0.06896 | Acc: 97.492\n",
      "Epoch 033: | Loss: 0.06594 | Acc: 97.667\n",
      "Epoch 034: | Loss: 0.06043 | Acc: 97.968\n",
      "Epoch 035: | Loss: 0.06049 | Acc: 97.810\n",
      "Epoch 036: | Loss: 0.05570 | Acc: 98.063\n",
      "Epoch 037: | Loss: 0.05065 | Acc: 98.429\n",
      "Epoch 038: | Loss: 0.05162 | Acc: 98.143\n",
      "Epoch 039: | Loss: 0.05760 | Acc: 97.730\n",
      "Epoch 040: | Loss: 0.04627 | Acc: 98.492\n",
      "Epoch 041: | Loss: 0.04665 | Acc: 98.190\n",
      "Epoch 042: | Loss: 0.04451 | Acc: 98.587\n",
      "Epoch 043: | Loss: 0.04316 | Acc: 98.683\n",
      "Epoch 044: | Loss: 0.04209 | Acc: 98.571\n",
      "Epoch 045: | Loss: 0.05444 | Acc: 97.952\n",
      "Epoch 046: | Loss: 0.04351 | Acc: 98.302\n",
      "Epoch 047: | Loss: 0.04417 | Acc: 98.413\n",
      "Epoch 048: | Loss: 0.05037 | Acc: 98.159\n",
      "Epoch 049: | Loss: 0.04891 | Acc: 98.048\n",
      "Epoch 050: | Loss: 0.04627 | Acc: 98.127\n"
     ]
    }
   ],
   "source": [
    "model2.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model2(X_batch)\n",
    "      \n",
    "        gene = torch.sigmoid(y_pred) \n",
    "        #gene = y_pred\n",
    "        px = pd.DataFrame(gene).astype(\"float\")\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.  Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[5.439192e-05]], dtype=float32), array([[6.1551946e-06]], dtype=float32), array([[0.99785775]], dtype=float32), array([[0.02226041]], dtype=float32), array([[3.1514237e-06]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "gene_list =[]\n",
    "y_test_pred_list= [] \n",
    "input_list = []\n",
    "\n",
    "model2.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model2(X_batch)\n",
    "        input = X_batch\n",
    "        gene = model2(X_batch)   \n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        gene = torch.sigmoid(gene) \n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        \n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        gene_list.append(gene.cpu().numpy())\n",
    "        y_test_pred_list.append(y_test_pred.cpu().numpy())\n",
    "        input_list.append(input.cpu().numpy())\n",
    "\n",
    " \n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "\n",
    "\n",
    "gene_list = [a.squeeze().tolist() for a in gene_list]\n",
    "                          \n",
    "input_list =[a.squeeze().tolist() for a in input_list]                  \n",
    "    \n",
    "\n",
    "\n",
    "#print(input_list[0])\n",
    "#print(gene[:10])\n",
    " \n",
    "print(y_test_pred_list[:5])\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.  Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1552,   28],\n",
       "       [ 142,  245]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14.  Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1580\n",
      "           1       0.90      0.63      0.74       387\n",
      "\n",
      "    accuracy                           0.91      1967\n",
      "   macro avg       0.91      0.81      0.85      1967\n",
      "weighted avg       0.91      0.91      0.91      1967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.  Save and Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  0.000054\n",
      "1  0.000006\n",
      "2  0.997858\n",
      "3  0.022260\n",
      "4  0.000003\n"
     ]
    }
   ],
   "source": [
    "project_dir = '/sasinside/userdata/gegrab/resources/hmeq'\n",
    "torch.save(model2.state_dict(), project_dir +'/'+ 'CALLCENTER_PyTorch_Classifier.pt')\n",
    "model3 = binaryClassification()\n",
    "model3.load_state_dict(torch.load(project_dir + '/' + 'CALLCENTER_PyTorch_Classifier.pt'))\n",
    "model3.eval()\n",
    "\n",
    "scaler2 = pickle.load(open(project_dir + '/' + 'callcenter_pytorch_scaler.pickle', 'rb'))\n",
    "\n",
    "#inputMatrix = scaler2.transform(X_test)\n",
    "#already scaled!!!\n",
    "inputMatrix = X_test\n",
    "\n",
    "X_test_var = Variable(torch.FloatTensor(inputMatrix), requires_grad=True) \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    predict_proba =model3(X_test_var)\n",
    "    predict_proba = torch.sigmoid(predict_proba)   \n",
    "    predict_proba = pd.DataFrame(predict_proba).astype(\"float\")\n",
    "    \n",
    "    \n",
    "print(predict_proba[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  0.000054\n",
      "1  0.000006\n",
      "2  0.997858\n",
      "3  0.022260\n",
      "4  0.000003\n",
      "          0\n",
      "0  0.000054\n",
      "1  0.000006\n",
      "2  0.997858\n",
      "3  0.022260\n",
      "4  0.000003\n"
     ]
    }
   ],
   "source": [
    "#pt vs pickle??\n",
    "\n",
    "project_dir = '/sasinside/userdata/gegrab/resources/hmeq'\n",
    "torch.save(model2.state_dict(), project_dir +'/'+ 'CALLCENTER_PyTorch_Classifier.pt')\n",
    "model3 = binaryClassification()\n",
    "model3.load_state_dict(torch.load(project_dir + '/' + 'CALLCENTER_PyTorch_Classifier.pt'))\n",
    "model3.eval()\n",
    "\n",
    "#original method\n",
    "torch.save(model2, project_dir +'/'+ 'CALLCENTER_PyTorch_Classifier_orig.pt')\n",
    "model4=torch.load(project_dir +'/' + 'CALLCENTER_PyTorch_Classifier_orig.pt')\n",
    "\n",
    "scaler2 = pickle.load(open(project_dir + '/' + 'callcenter_pytorch_scaler.pickle', 'rb'))\n",
    "\n",
    "\n",
    "modelx =  binaryClassification()\n",
    "modelx.load_state_dict(torch.load(\"/sasinside/userdata/gegrab/resources/hmeq/CALLCENTER_PyTorch_Classifier.pt\"))\n",
    "modelx.eval()\n",
    "    \n",
    "\n",
    "#inputMatrix = scaler2.transform(X_test)\n",
    "#already scaled!!!\n",
    "inputMatrix = X_test\n",
    "\n",
    "X_test_var = Variable(torch.FloatTensor(inputMatrix), requires_grad=True) \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    predict_proba =model3(X_test_var)\n",
    "    predict_proba = torch.sigmoid(predict_proba)   \n",
    "    predict_proba = pd.DataFrame(predict_proba).astype(\"float\")\n",
    "    \n",
    "    \n",
    "print(predict_proba[:5])\n",
    "\n",
    "with torch.no_grad():\n",
    "    predict_proba =model4(X_test_var)\n",
    "    predict_proba = torch.sigmoid(predict_proba)   \n",
    "    predict_proba = pd.DataFrame(predict_proba).astype(\"float\")\n",
    "    \n",
    "    \n",
    "print(predict_proba[:5])\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"CALL_CENTER_ID\", \"DAILY_CALLS\", \"MONTHLY_CALLS\", \"CALL_TARGET\", \"REASON\", \"MONTHS_CUSTOMER\", \"NEGATIVE_RATING\", \"DAYS_PROD_OUT_OF_SERVICE\", \"PRODUCT_AGE\", \"CALL_INQUIRIES\", \"NUM_CALLERS\", \"CALL_TIME\", \"PRODUCT_TYPE\"\n",
      "\n",
      "CALL_CENTER_ID, DAILY_CALLS, MONTHLY_CALLS, CALL_TARGET, REASON, MONTHS_CUSTOMER, NEGATIVE_RATING, DAYS_PROD_OUT_OF_SERVICE, PRODUCT_AGE, CALL_INQUIRIES, NUM_CALLERS, CALL_TIME, PRODUCT_TYPE\n"
     ]
    }
   ],
   "source": [
    "input_params = ''\n",
    "for col in callcenter.columns:\n",
    "    input_params += col\n",
    "    if col != callcenter.columns[-1]:\n",
    "        input_params += ', '\n",
    "\n",
    "input_cols = ''\n",
    "for col in callcenter.columns:\n",
    "    input_cols += \"\\\"\" + col + \"\\\"\"\n",
    "    if col != callcenter.columns[-1]:\n",
    "        input_cols += ', '\n",
    "\n",
    "\n",
    "print(input_cols)\n",
    "print(\"\")\n",
    "print(input_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model\n",
    "import onnx\n",
    "torch.onnx.export(model3,               # model being run\n",
    "                  X_test_var[0:2],                         # model input (or a tuple for multiple inputs)\n",
    "                  \"/sasinside/userdata/gegrab/resources/hmeq/CALLCENTER_PyTorch_ONNX.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to            \n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'] # the model's output names\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31952/1703002696.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  ort_outs = torch.FloatTensor(ort_session.run(None, ort_inputs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[5.4392e-05],\n",
       "         [6.1552e-06]]),\n",
       " torch.Size([1967, 18]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime as rt\n",
    "ort_session = rt.InferenceSession(\"/sasinside/userdata/gegrab/resources/hmeq/CALLCENTER_PyTorch_ONNX.onnx\")\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(X_test_var[0:2])} \n",
    "ort_outs = torch.FloatTensor(ort_session.run(None, ort_inputs))\n",
    "     \n",
    "     \n",
    "predict_proba = torch.sigmoid(ort_outs)   \n",
    "predict_proba[0], X_test_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(CALL_CENTER_ID, DAILY_CALLS, MONTHLY_CALLS, CALL_TARGET, REASON, MONTHS_CUSTOMER, NEGATIVE_RATING, DAYS_PROD_OUT_OF_SERVICE, PRODUCT_AGE, CALL_INQUIRIES, NUM_CALLERS, CALL_TIME, PRODUCT_TYPE):\n",
    "    \"Output: P_ESCALATED\"\n",
    "        \n",
    "    #global pred_onnx\n",
    "    \n",
    "    import onnxruntime as rt\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    from torch.autograd import Variable\n",
    "     \n",
    "    \n",
    "    inputArray = pd.DataFrame([[CALL_CENTER_ID, DAILY_CALLS, MONTHLY_CALLS, CALL_TARGET, REASON, MONTHS_CUSTOMER, NEGATIVE_RATING, DAYS_PROD_OUT_OF_SERVICE, PRODUCT_AGE, CALL_INQUIRIES, NUM_CALLERS, CALL_TIME, PRODUCT_TYPE]],\n",
    "                              columns = [\"CALL_CENTER_ID\", \"DAILY_CALLS\", \"MONTHLY_CALLS\", \"CALL_TARGET\", \"REASON\", \"MONTHS_CUSTOMER\", \"NEGATIVE_RATING\", \"DAYS_PROD_OUT_OF_SERVICE\", \"PRODUCT_AGE\", \"CALL_INQUIRIES\", \"NUM_CALLERS\", \"CALL_TIME\", \"PRODUCT_TYPE\"]\n",
    "                               )\n",
    "    \n",
    "    dummy=inputArray\n",
    "     \n",
    "    inputArray = pd.concat([inputArray,dummy], sort=False)\n",
    "    \n",
    "      \n",
    "    def preprocessing(df, ohe_loc = None):\n",
    "\n",
    "        categorical_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    \n",
    "        with open(ohe_loc, \"rb\") as ohe_file:\n",
    "            ohe = pickle.load(ohe_file) \n",
    "        \n",
    "        enc = ohe.transform(df[categorical_cols])\n",
    "    \n",
    "        df[ohe.get_feature_names(categorical_cols).tolist()] = pd.DataFrame(enc, index=df.index)\n",
    "\n",
    "        df.drop(categorical_cols,1,inplace=True)\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "    \n",
    "        return df\n",
    "\n",
    "    \n",
    "    inputArray.fillna(pickle.load(open('/sasinside/userdata/gegrab/resources/hmeq/callcenter_impute.pickle', 'rb')), inplace=True)\n",
    "    inputArray.REASON.replace(np.nan,'ProdFailure',regex = True, inplace=True)\n",
    "    inputArray.PRODUCT_TYPE.replace(np.nan,'Other',regex = True, inplace=True)\n",
    "\n",
    "\n",
    "    inputArray.drop(['CALL_CENTER_ID'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    inputArray = preprocessing(inputArray, \"/sasinside/userdata/gegrab/resources/hmeq/callcenter_encoder.pickle\")\n",
    "    \n",
    "     \n",
    "    \n",
    "    scaler2 = pickle.load(open(\"/sasinside/userdata/gegrab/resources/hmeq/callcenter_pytorch_scaler.pickle\", 'rb'))\n",
    "    \n",
    "    inputMatrix = scaler2.transform(inputArray)\n",
    "    \n",
    "     \n",
    "    \n",
    "    #X_test_var = Variable(torch.FloatTensor(inputMatrix), requires_grad=True) \n",
    "    X_test_var = torch.FloatTensor(inputMatrix)\n",
    "     \n",
    "\n",
    "\n",
    "    ort_session = rt.InferenceSession(\"/sasinside/userdata/gegrab/resources/hmeq/CALLCENTER_PyTorch_ONNX.onnx\")\n",
    "\n",
    "    def to_numpy(tensor):\n",
    "        return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(X_test_var)} \n",
    "    ort_outs = torch.FloatTensor(ort_session.run(None, ort_inputs))\n",
    "     \n",
    "     \n",
    "    predict_proba = torch.sigmoid(ort_outs)   \n",
    "    #predict_proba = predict_proba.numpy()\n",
    "    \n",
    "\n",
    "    P_ESCALATED = float(predict_proba[0][0])\n",
    "     \n",
    "     \n",
    "    return (P_ESCALATED)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00541743915528059\n",
      "0.012170938774943352\n",
      "0.0012175309238955379\n",
      "7.953982276376337e-06\n",
      "0.032101068645715714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sasinside/miniconda3/envs/pytorch2021/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/tmp/ipykernel_31952/3096643007.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(categorical_cols,1,inplace=True)\n",
      "/sasinside/miniconda3/envs/pytorch2021/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/tmp/ipykernel_31952/3096643007.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(categorical_cols,1,inplace=True)\n",
      "/sasinside/miniconda3/envs/pytorch2021/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/tmp/ipykernel_31952/3096643007.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(categorical_cols,1,inplace=True)\n",
      "/sasinside/miniconda3/envs/pytorch2021/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/tmp/ipykernel_31952/3096643007.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(categorical_cols,1,inplace=True)\n",
      "/sasinside/miniconda3/envs/pytorch2021/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/tmp/ipykernel_31952/3096643007.py:38: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(categorical_cols,1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import pandas as pd\n",
    "testdf= pd.read_csv('Data_orig/CALLCENTER_test2.csv')  \n",
    " \n",
    "\n",
    "    \n",
    "for i in range(5):\n",
    "    print(execute(**testdf.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_code = \"\"\"\n",
    "def execute(CALL_CENTER_ID, DAILY_CALLS, MONTHLY_CALLS, CALL_TARGET, REASON, MONTHS_CUSTOMER, NEGATIVE_RATING, DAYS_PROD_OUT_OF_SERVICE, PRODUCT_AGE, CALL_INQUIRIES, NUM_CALLERS, CALL_TIME, PRODUCT_TYPE):\n",
    "    \"Output: P_ESCALATED\"\n",
    "        \n",
    "    #global pred_onnx\n",
    "    \n",
    "    import onnxruntime as rt\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    from torch.autograd import Variable\n",
    "     \n",
    "    \n",
    "    inputArray = pd.DataFrame([[CALL_CENTER_ID, DAILY_CALLS, MONTHLY_CALLS, CALL_TARGET, REASON, MONTHS_CUSTOMER, NEGATIVE_RATING, DAYS_PROD_OUT_OF_SERVICE, PRODUCT_AGE, CALL_INQUIRIES, NUM_CALLERS, CALL_TIME, PRODUCT_TYPE]],\n",
    "                              columns = [\"CALL_CENTER_ID\", \"DAILY_CALLS\", \"MONTHLY_CALLS\", \"CALL_TARGET\", \"REASON\", \"MONTHS_CUSTOMER\", \"NEGATIVE_RATING\", \"DAYS_PROD_OUT_OF_SERVICE\", \"PRODUCT_AGE\", \"CALL_INQUIRIES\", \"NUM_CALLERS\", \"CALL_TIME\", \"PRODUCT_TYPE\"]\n",
    "                               )\n",
    "    \n",
    "    dummy=inputArray\n",
    "     \n",
    "    inputArray = pd.concat([inputArray,dummy], sort=False)\n",
    "    \n",
    "      \n",
    "    def preprocessing(df, ohe_loc = None):\n",
    "\n",
    "        categorical_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    \n",
    "        with open(ohe_loc, \"rb\") as ohe_file:\n",
    "            ohe = pickle.load(ohe_file) \n",
    "        \n",
    "        enc = ohe.transform(df[categorical_cols])\n",
    "    \n",
    "        df[ohe.get_feature_names(categorical_cols).tolist()] = pd.DataFrame(enc, index=df.index)\n",
    "\n",
    "        df.drop(categorical_cols,1,inplace=True)\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "    \n",
    "        return df\n",
    "\n",
    "    \n",
    "    inputArray.fillna(pickle.load(open('/sasinside/userdata/gegrab/resources/hmeq/callcenter_impute.pickle', 'rb')), inplace=True)\n",
    "    inputArray.REASON.replace(np.nan,'ProdFailure',regex = True, inplace=True)\n",
    "    inputArray.PRODUCT_TYPE.replace(np.nan,'Other',regex = True, inplace=True)\n",
    "\n",
    "\n",
    "    inputArray.drop(['CALL_CENTER_ID'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    inputArray = preprocessing(inputArray, \"/sasinside/userdata/gegrab/resources/hmeq/callcenter_encoder.pickle\")\n",
    "    \n",
    "     \n",
    "    \n",
    "    scaler2 = pickle.load(open(\"/sasinside/userdata/gegrab/resources/hmeq/callcenter_pytorch_scaler.pickle\", 'rb'))\n",
    "    \n",
    "    inputMatrix = scaler2.transform(inputArray)\n",
    "    \n",
    "     \n",
    "    \n",
    "    #X_test_var = Variable(torch.FloatTensor(inputMatrix), requires_grad=True) \n",
    "    X_test_var = torch.FloatTensor(inputMatrix)\n",
    "     \n",
    "\n",
    "\n",
    "    ort_session = rt.InferenceSession(\"/sasinside/userdata/gegrab/resources/hmeq/CALLCENTER_PyTorch_ONNX.onnx\")\n",
    "\n",
    "    def to_numpy(tensor):\n",
    "        return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(X_test_var)} \n",
    "    ort_outs = torch.FloatTensor(ort_session.run(None, ort_inputs))\n",
    "     \n",
    "     \n",
    "    predict_proba = torch.sigmoid(ort_outs)   \n",
    "    #predict_proba = predict_proba.numpy()\n",
    "    \n",
    "\n",
    "    P_ESCALATED = float(predict_proba[0][0])\n",
    "     \n",
    "     \n",
    "    return (P_ESCALATED)\"\"\"\n",
    "\n",
    "\n",
    "f = open('Data_orig/CALLCENTER_Pytorch_ONNX.py',\"w+\")\n",
    "f.write(score_code)\n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 2022 Latest",
   "language": "python",
   "name": "pytorch2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
